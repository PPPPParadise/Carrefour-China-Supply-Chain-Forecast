{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from os.path import abspath\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_qty(all_regular_forecast, row, week_start_day):\n",
    "    df_line = all_regular_forecast[(all_forecast[\"item_code\"] == row.item_code)\n",
    "                           & (all_forecast[\"sub_code\"] == row.sub_code)\n",
    "                           & (all_forecast[\"dept_code\"] == row.dept_code)\n",
    "                           & (all_forecast[\"week_start_day\"] == week_start_day)]\n",
    "    if len(df_line) > 0:\n",
    "        return str(df_line['order_qty'].iloc[0])\n",
    "    else:\n",
    "        return \"0\"\n",
    "\n",
    "\n",
    "def get_dm_qty(all_dm_forecast, row, week_start_day):\n",
    "    df_line = all_dm_forecast[(all_forecast[\"item_code\"] == row.item_code)\n",
    "                           & (all_forecast[\"sub_code\"] == row.sub_code)\n",
    "                           & (all_forecast[\"dept_code\"] == row.dept_code)\n",
    "                           & (all_forecast[\"week_start_day\"] == week_start_day)]\n",
    "\n",
    "    if len(df_line) > 0:\n",
    "        return str(df_line['dm_qty'].iloc[0])\n",
    "    else:\n",
    "        return \"0\"\n",
    "\n",
    "\n",
    "def write_forecast_file(con_holding, supplier_name, forecast_file,\n",
    "                        items_df, all_regular_forecast, all_dm_forecast,\n",
    "                        date_str_list, record_folder, output_folder):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.append(\n",
    "        ['Supplier_name', 'Barcode', 'Department_code', 'Item_code',\n",
    "         'Sub_code', 'Item_desc_chn', 'Item_desc_eng',\n",
    "         f'Week1_{date_str_list[0]}_Permanent_Box', f'Week1_{date_str_list[0]}_DM_Box',\n",
    "         f'Week2_{date_str_list[1]}_Permanent_Box', f'Week2_{date_str_list[1]}_DM_Box',\n",
    "         f'Week3_{date_str_list[2]}_Permanent_Box', f'Week3_{date_str_list[2]}_DM_Box',\n",
    "         f'Week4_{date_str_list[3]}_Permanent_Box', f'Week4_{date_str_list[3]}_DM_Box',\n",
    "         f'Week5_{date_str_list[4]}_Permanent_Box', f'Week5_{date_str_list[4]}_DM_Box',\n",
    "         f'Week6_{date_str_list[5]}_Permanent_Box', f'Week6_{date_str_list[5]}_DM_Box',\n",
    "         f'Week7_{date_str_list[6]}_Permanent_Box', f'Week7_{date_str_list[6]}_DM_Box',\n",
    "         f'Week8_{date_str_list[7]}_Permanent_Box', f'Week8_{date_str_list[7]}_DM_Box',\n",
    "         f'Week9_{date_str_list[8]}_Permanent_Box', f'Week9_{date_str_list[8]}_DM_Box'])\n",
    "\n",
    "    for index, row in items_df[items_df[\"holding_code\"] == con_holding].iterrows():\n",
    "        ws.append([supplier_name, row.primary_barcode,\n",
    "                   row.dept_code, row.item_code, row.sub_code, row.item_name_local, row.item_name_english,\n",
    "                   get_order_qty(all_regular_forecast, row, date_str_list[0]), get_dm_qty(all_dm_forecast, row, date_str_list[0]),\n",
    "                   get_order_qty(all_regular_forecast, row, date_str_list[1]), get_dm_qty(all_dm_forecast, row, date_str_list[1]),\n",
    "                   get_order_qty(all_regular_forecast, row, date_str_list[2]), get_dm_qty(all_dm_forecast, row, date_str_list[2]),\n",
    "                   get_order_qty(all_regular_forecast, row, date_str_list[3]), get_dm_qty(all_dm_forecast, row, date_str_list[3]),\n",
    "                   get_order_qty(all_regular_forecast, row, date_str_list[4]), get_dm_qty(all_dm_forecast, row, date_str_list[4]),\n",
    "                   get_order_qty(all_regular_forecast, row, date_str_list[5]), get_dm_qty(all_dm_forecast, row, date_str_list[5]),\n",
    "                   get_order_qty(all_regular_forecast, row, date_str_list[6]), get_dm_qty(all_dm_forecast, row, date_str_list[6]),\n",
    "                   get_order_qty(all_regular_forecast, row, date_str_list[7]), get_dm_qty(all_dm_forecast, row, date_str_list[7]),\n",
    "                   get_order_qty(all_regular_forecast, row, date_str_list[8]), get_dm_qty(all_dm_forecast, row, date_str_list[8])])\n",
    "\n",
    "    wb.save(forecast_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = '20190916'\n",
    "\n",
    "run_date = datetime.datetime.strptime(date_str, '%Y%m%d').date()\n",
    "\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = '--jars /data/jupyter/kudu-spark2_2.11-1.8.0.jar pyspark-shell'\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Generate order forecast file\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"spark.driver.memory\", '8g') \\\n",
    "    .config(\"spark.executor.memory\", '6g') \\\n",
    "    .config(\"spark.num.executors\", '14') \\\n",
    "    .config(\"hive.exec.compress.output\", 'false') \\\n",
    "    .config(\"spark.sql.crossJoin.enabled\", 'true') \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", '-1') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sqlc = SQLContext(sc)\n",
    "# -\n",
    "\n",
    "\n",
    "w1_start_date = run_date\n",
    "w2_start_date = run_date + timedelta(weeks=1)\n",
    "w3_start_date = run_date + timedelta(weeks=2)\n",
    "w4_start_date = run_date + timedelta(weeks=3)\n",
    "w5_start_date = run_date + timedelta(weeks=4)\n",
    "w6_start_date = run_date + timedelta(weeks=5)\n",
    "w7_start_date = run_date + timedelta(weeks=6)\n",
    "w8_start_date = run_date + timedelta(weeks=7)\n",
    "w9_start_date = run_date + timedelta(weeks=8)\n",
    "w10_start_date = run_date + timedelta(weeks=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_sql = \"\"\"\n",
    "    SELECT\n",
    "        dc.holding_code,\n",
    "        dc.primary_barcode,\n",
    "        dc.dept_code,\n",
    "        dc.item_code,\n",
    "        dc.sub_code,\n",
    "        dc.item_name_local,\n",
    "        dc.item_name_english\n",
    "    FROM vartefact.v_forecast_inscope_dc_item_details dc\n",
    "\"\"\".replace(\"\\n\", \" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = sqlc.sql(items_sql).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross docking items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdock_orders_sql = \"\"\"\n",
    "        SELECT\n",
    "            dc.dept_code,\n",
    "            dc.item_code,\n",
    "            dc.sub_code,\n",
    "            wst.date_key week_start_day,\n",
    "            sum(\n",
    "                ceil(\n",
    "                    coalesce(ord.order_qty, 0) * (2 - coalesce(sl.service_level, 1)) / dc.qty_per_box\n",
    "                )\n",
    "            ) order_qty\n",
    "        FROM\n",
    "            vartefact.forecast_calendar cal\n",
    "            INNER JOIN vartefact.forecast_calendar wst ON wst.week_index = cal.week_index\n",
    "            AND wst.weekday_short = 'Mon'\n",
    "            INNER JOIN vartefact.v_forecast_inscope_dc_item_details dc ON dc.rotation = 'X'\n",
    "            LEFT OUTER JOIN vartefact.forecast_xdock_orders ord ON ord.order_day = cal.date_key\n",
    "            AND ord.item_code = dc.item_code\n",
    "            AND ord.sub_code = dc.sub_code\n",
    "            AND ord.dept_code = dc.dept_code\n",
    "            AND ord.order_day >='{0}'\n",
    "            AND ord.order_day <'{2}'\n",
    "            LEFT OUTER JOIN vartefact.service_level_safety2_vinc sl ON ord.item_code = sl.item_code\n",
    "            AND ord.sub_code = sl.sub_code\n",
    "            AND ord.dept_code = sl.dept_code\n",
    "        WHERE\n",
    "            wst.date_key >='{0}'\n",
    "            and wst.date_key <='{1}'\n",
    "        GROUP BY\n",
    "            dc.dept_code,\n",
    "            dc.item_code,\n",
    "            dc.sub_code,\n",
    "            wst.date_key \n",
    "        \n",
    "            \"\"\".replace(\"\\n\", \" \") \\\n",
    "        .format(\n",
    "        w1_start_date.strftime(\"%Y%m%d\"),\n",
    "        w9_start_date.strftime(\"%Y%m%d\"),\n",
    "        w10_start_date.strftime(\"%Y%m%d\"))\n",
    "\n",
    "xdock_orders = sqlc.sql(xdock_orders_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdock_orders_df = xdock_orders.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdock_dm_orders_sql = \"\"\"\n",
    "        SELECT\n",
    "            dc.dept_code,\n",
    "            dc.item_code,\n",
    "            dc.sub_code,\n",
    "            wst.date_key week_start_day,\n",
    "            sum(ceil(coalesce(dm.order_qty, 0) / dc.qty_per_box)) dm_qty\n",
    "        FROM\n",
    "            vartefact.forecast_calendar cal\n",
    "            INNER JOIN vartefact.forecast_calendar wst ON wst.week_index = cal.week_index\n",
    "            AND wst.weekday_short = 'Mon'\n",
    "            INNER JOIN vartefact.v_forecast_inscope_dc_item_details dc ON dc.rotation = 'X'\n",
    "            LEFT OUTER JOIN vartefact.forecast_dm_orders dm ON dm.first_order_date = cal.date_key\n",
    "            AND dm.dept_code = dc.dept_code\n",
    "            AND dm.item_code = dc.item_code\n",
    "            AND dm.sub_code = dc.sub_code\n",
    "            AND dm.first_order_date >='{0}'\n",
    "            AND dm.first_order_date <'{2}'\n",
    "        WHERE\n",
    "            wst.date_key >='{0}'\n",
    "            and wst.date_key <='{1}'\n",
    "        GROUP BY\n",
    "            dc.dept_code,\n",
    "            dc.item_code,\n",
    "            dc.sub_code,\n",
    "            wst.date_key \n",
    "        \n",
    "            \"\"\".replace(\"\\n\", \" \") \\\n",
    "        .format(\n",
    "        w1_start_date.strftime(\"%Y%m%d\"),\n",
    "        w9_start_date.strftime(\"%Y%m%d\"),\n",
    "        w10_start_date.strftime(\"%Y%m%d\"))\n",
    "\n",
    "xdock_dm_orders = sqlc.sql(xdock_dm_orders_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdock_dm_orders_df = xdock_dm_orders.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_orders_sql = \"\"\"\n",
    "        SELECT\n",
    "            dc.dept_code,\n",
    "            dc.item_code,\n",
    "            dc.sub_code,\n",
    "            wst.date_key week_start_day,\n",
    "            sum(\n",
    "                ceil(\n",
    "                    coalesce(ord.order_qty, 0) * (2 - coalesce(sl.service_level, 1)) / dc.qty_per_box\n",
    "                )\n",
    "            ) order_qty\n",
    "        FROM\n",
    "            vartefact.forecast_calendar cal\n",
    "            INNER JOIN vartefact.forecast_calendar wst ON wst.week_index = cal.week_index\n",
    "            AND wst.weekday_short = 'Mon'\n",
    "            INNER JOIN vartefact.v_forecast_inscope_dc_item_details dc ON dc.rotation != 'X'\n",
    "            LEFT OUTER JOIN vartefact.forecast_dc_orders ord ON ord.order_day = cal.date_key\n",
    "            AND ord.item_code = dc.item_code\n",
    "            AND ord.sub_code = dc.sub_code\n",
    "            AND ord.dept_code = dc.dept_code\n",
    "            AND ord.order_day >='{0}'\n",
    "            AND ord.order_day <'{2}'\n",
    "            LEFT OUTER JOIN vartefact.service_level_safety2_vinc sl ON ord.item_code = sl.item_code\n",
    "            AND ord.sub_code = sl.sub_code\n",
    "            AND ord.dept_code = sl.dept_code\n",
    "        WHERE\n",
    "            wst.date_key >='{0}'\n",
    "            and wst.date_key <='{1}'\n",
    "        GROUP BY\n",
    "            dc.dept_code,\n",
    "            dc.item_code,\n",
    "            dc.sub_code,\n",
    "            wst.date_key\n",
    "            \"\"\".replace(\"\\n\", \" \") \\\n",
    "        .format(\n",
    "        w1_start_date.strftime(\"%Y%m%d\"),\n",
    "        w9_start_date.strftime(\"%Y%m%d\"),\n",
    "        w10_start_date.strftime(\"%Y%m%d\"))\n",
    "\n",
    "dc_orders = sqlc.sql(dc_orders_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_orders_df = dc_orders.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_dm_orders_sql = \"\"\"\n",
    "        SELECT\n",
    "            dc.dept_code,\n",
    "            dc.item_code,\n",
    "            dc.sub_code,\n",
    "            wst.date_key week_start_day,\n",
    "            sum(ceil(coalesce(dm.order_qty, 0) / dc.qty_per_box)) dm_qty\n",
    "        FROM\n",
    "            vartefact.forecast_calendar cal\n",
    "            INNER JOIN vartefact.forecast_calendar wst ON wst.week_index = cal.week_index\n",
    "            AND wst.weekday_short = 'Mon'\n",
    "            INNER JOIN vartefact.v_forecast_inscope_dc_item_details dc ON dc.rotation != 'X'\n",
    "            LEFT OUTER JOIN vartefact.forecast_dm_dc_orders dm ON dm.first_order_date = cal.date_key\n",
    "            AND dm.item_code = dc.item_code\n",
    "            AND dm.sub_code = dc.sub_code\n",
    "            AND dm.first_order_date >='{0}'\n",
    "            AND dm.first_order_date <'{2}'\n",
    "        WHERE\n",
    "            wst.date_key >='{0}'\n",
    "            and wst.date_key <='{1}'\n",
    "        GROUP BY\n",
    "            dc.dept_code,\n",
    "            dc.item_code,\n",
    "            dc.sub_code,\n",
    "            wst.date_key\n",
    "            \"\"\".replace(\"\\n\", \" \") \\\n",
    "        .format(\n",
    "        w1_start_date.strftime(\"%Y%m%d\"),\n",
    "        w9_start_date.strftime(\"%Y%m%d\"),\n",
    "        w10_start_date.strftime(\"%Y%m%d\"))\n",
    "\n",
    "dc_dm_orders = sqlc.sql(dc_dm_orders_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_dm_orders_df = dc_dm_orders.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regular_forecast = pd.concat([xdock_orders_df, dc_orders_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dm_forecast = pd.concat([xdock_dm_orders_df, dc_dm_orders_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/data/jupyter/ws_house/Carrefour_DM\"\n",
    "\n",
    "run_date_str = run_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "w1_date_str = w1_start_date.strftime(\"%Y%m%d\")\n",
    "w2_date_str = w2_start_date.strftime(\"%Y%m%d\")\n",
    "w3_date_str = w3_start_date.strftime(\"%Y%m%d\")\n",
    "w4_date_str = w4_start_date.strftime(\"%Y%m%d\")\n",
    "w5_date_str = w5_start_date.strftime(\"%Y%m%d\")\n",
    "w6_date_str = w6_start_date.strftime(\"%Y%m%d\")\n",
    "w7_date_str = w7_start_date.strftime(\"%Y%m%d\")\n",
    "w8_date_str = w8_start_date.strftime(\"%Y%m%d\")\n",
    "w9_date_str = w9_start_date.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_holding = \"700\"\n",
    "    supplier_name = \"Unilever Services (Hefei) Co. Ltd.\"\n",
    "\n",
    "    forecast_file = forecast_file_name.format(con_holding, run_date_str)\n",
    "\n",
    "    write_forecast_file(con_holding, supplier_name, forecast_file,\n",
    "                        items_df, all_regular_forecast, all_dm_forecast,\n",
    "                        date_str_list, record_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "con_holding = \"002\"\n",
    "supplier_name = \"Shanghai Nestle products Service Co.,Ltd\"\n",
    "\n",
    "forecast_file = f\"Carrefour_Order_Forecast_DC_level_{con_holding}_{run_date_str}.xlsx\"\n",
    "\n",
    "write_forecast_file(con_holding, supplier_name, forecast_file, items_df, all_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_holding = \"693\"\n",
    "supplier_name = \"Procter&Gamble (China) Sales Co.,Ltd.\"\n",
    "\n",
    "forecast_file = f\"Carrefour_Order_Forecast_DC_level_{con_holding}_{run_date_str}.xlsx\"\n",
    "\n",
    "write_forecast_file(con_holding, supplier_name, forecast_file, items_df, all_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
