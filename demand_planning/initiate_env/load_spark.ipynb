{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_or = pd.read_excel('store.xlsx', 'ordinary', header=0, dtype=str).fillna(\"\")\n",
    "data_or.columns = ['store_code', 'store_cn_name', 'store_en_name',\n",
    "                   'dept', 'A-order_day', 'A-delivery_day', 'B-order_day', 'B-delivery_day', 'remarks']\n",
    "\n",
    "data_or_A = data_or[['store_code', 'store_cn_name', 'store_en_name',\n",
    "                     'dept', 'A-order_day', 'A-delivery_day', 'remarks']]\n",
    "\n",
    "data_or_A.columns = ['store_code', 'store_cn_name', 'store_en_name',\n",
    "                     'dept', 'order_type', 'deliver_type', 'remarks']\n",
    "data_or_A['class'] = 'A'\n",
    "\n",
    "data_or_B = data_or[['store_code', 'store_cn_name', 'store_en_name',\n",
    "                     'dept', 'B-order_day', 'B-delivery_day', 'remarks']]\n",
    "\n",
    "data_or_B.columns = ['store_code', 'store_cn_name', 'store_en_name',\n",
    "                     'dept', 'order_type', 'deliver_type', 'remarks']\n",
    "\n",
    "data_or_B['class'] = 'B'\n",
    "\n",
    "data_or_f = pd.concat([data_or_A, data_or_B], ignore_index=True)\n",
    "\n",
    "mapping_or = pd.read_excel('order_deliver_mapping.xlsx', 'ordinary', header=0, dtype=str)\n",
    "\n",
    "res_or = data_or_f.merge(mapping_or, left_on=['class', 'order_type', 'deliver_type'], \\\n",
    "                         right_on=['class', 'order_type', 'deliver_type'])\n",
    "\n",
    "res_or[\"week_shift\"] = res_or[\"week_shift\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = res_or[['store_code', 'store_cn_name', 'store_en_name','dept']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dp = res_or[['store_code','dept']].drop_duplicates()\n",
    "\n",
    "store_dp[\"dept1\"] = store_dp[\"dept\"]\n",
    "\n",
    "store_dp = store_dp.set_index(['store_code','dept'])\n",
    "\n",
    "store_dp = store_dp.stack().str.split(',', expand=True) \\\n",
    "    .stack().apply(pd.Series).stack() \\\n",
    "    .unstack(level=2).reset_index(-1, drop=True).reset_index()\n",
    "\n",
    "store_dp.columns =['store_code', 'dept', 'dummy', 'dept_code']\n",
    "\n",
    "store_dp.dept_code = store_dp.dept_code.str.split(' ', 1, expand=True)\n",
    "\n",
    "store_dp = store_dp[['store_code', 'dept', 'dept_code']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "from os.path import expanduser, join, abspath\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = '--jars /data/jupyter/kudu-spark2_2.11-1.8.0.jar pyspark-shell'\n",
    "\n",
    "sc = SparkSession.builder \\\n",
    "    .appName(\"process_store_file\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"hive.exec.compress.output\", 'false') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sqlc = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "onstock_df = sqlc.createDataFrame(res_or)\n",
    "onstock_df.write.mode(\"overwrite\").saveAsTable(\"vartefact.ordinary_onstock_order_deliver_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = sqlc.createDataFrame(stores)\n",
    "store_df.write.mode(\"overwrite\").saveAsTable(\"vartefact.dm_stores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dp = sqlc.createDataFrame(store_dp)\n",
    "store_dp.write.mode(\"overwrite\").saveAsTable(\"vartefact.dm_stores_dept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.table(\"vartefact.dm_stores_dept\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.sql"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
