{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from os.path import abspath\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "endofcell": "--"
   },
   "outputs": [],
   "source": [
    "warehouse_location = abspath('spark-warehouse')\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = '--jars /data/jupyter/kudu-spark2_2.11-1.8.0.jar pyspark-shell'\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Load order forecast file to database\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"spark.driver.memory\", '8g') \\\n",
    "    .config(\"spark.executor.memory\", '6g') \\\n",
    "    .config(\"spark.num.executors\", '14') \\\n",
    "    .config(\"hive.exec.compress.output\", 'false') \\\n",
    "    .config(\"spark.sql.crossJoin.enabled\", 'true') \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", '-1') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sqlc = SQLContext(sc)\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weekly_forecast(excel_input, week_no, run_date, con_holding):\n",
    "    week_add = week_no - 1\n",
    "    \n",
    "    week_start_date = (run_date + timedelta(weeks=week_add)).strftime(\"%Y%m%d\")\n",
    "    \n",
    "    df = excel_input.loc[:, ['Department_code', 'Item_code', \n",
    "                  'Sub_code', 'Item_desc_chn', \n",
    "                  f'Week{week_no}_{week_start_date}_Permanent_Box', \n",
    "                  f'Week{week_no}_{week_start_date}_DM_Box']]\n",
    "    \n",
    "    df.columns = ['dept_code','item_code','sub_code', 'item_desc_chn','order_qty','dm_order_qty']\n",
    "    \n",
    "    df['con_holding'] = con_holding\n",
    "    df['week_start_day'] = week_start_date\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_df(excel_input, run_date, con_holding):\n",
    "    \n",
    "    result = pd.concat([extract_weekly_forecast(excel_input, 1, run_date, con_holding), \n",
    "                        extract_weekly_forecast(excel_input, 2, run_date, con_holding),\n",
    "                        extract_weekly_forecast(excel_input, 3, run_date, con_holding),\n",
    "                        extract_weekly_forecast(excel_input, 4, run_date, con_holding),\n",
    "                        extract_weekly_forecast(excel_input, 5, run_date, con_holding),\n",
    "                        extract_weekly_forecast(excel_input, 6, run_date, con_holding),\n",
    "                        extract_weekly_forecast(excel_input, 7, run_date, con_holding),\n",
    "                        extract_weekly_forecast(excel_input, 8, run_date, con_holding),\n",
    "                        extract_weekly_forecast(excel_input, 9, run_date, con_holding)], ignore_index=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = '20190909'\n",
    "\n",
    "run_date = datetime.datetime.strptime(date_str, '%Y%m%d').date()\n",
    "\n",
    "output_path = \"/data/jupyter/Carrefour-China-Supply-Chain-Forecast/output/forecast_files/\"\n",
    "\n",
    "run_date_str = run_date.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_holding = \"693\"\n",
    "\n",
    "file_name = 'Carrefour_Order_Forecast_DC_level_{0}_{1}.xlsx'.format(con_holding, run_date_str)\n",
    "    \n",
    "pg_excel_input = pd.read_excel(output_path + file_name, 'Sheet', header=0, dtype=str).fillna(\"0\")\n",
    "\n",
    "pg_df = get_res_df(pg_excel_input, run_date, con_holding)\n",
    "\n",
    "con_holding = \"002\"\n",
    "\n",
    "file_name = 'Carrefour_Order_Forecast_DC_level_{0}_{1}.xlsx'.format(con_holding, run_date_str)\n",
    "    \n",
    "ns_excel_input = pd.read_excel(output_path + file_name, 'Sheet', header=0, dtype=str).fillna(\"0\")\n",
    "\n",
    "ns_df = get_res_df(ns_excel_input, run_date, con_holding)\n",
    "\n",
    "con_holding = \"700\"\n",
    "\n",
    "file_name = 'Carrefour_Order_Forecast_DC_level_{0}_{1}.xlsx'.format(con_holding, run_date_str)\n",
    "    \n",
    "un_excel_input = pd.read_excel(output_path + file_name, 'Sheet', header=0, dtype=str).fillna(\"0\")\n",
    "\n",
    "un_df = get_res_df(un_excel_input, run_date, con_holding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([pg_df, ns_df, un_df], ignore_index=True)\n",
    "\n",
    "result_df = result_df.replace(np.NaN, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlc.createDataFrame(result_df).createOrReplaceTempView(\"weekly_forecast_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_dc_sql = \\\n",
    "    \"\"\"\n",
    "    INSERT OVERWRITE TABLE vartefact.forecast_weekly_forecast_file\n",
    "    PARTITION (run_date)\n",
    "    SELECT \n",
    "        week_start_day,\n",
    "        con_holding,\n",
    "        dept_code,\n",
    "        item_code,\n",
    "        sub_code,\n",
    "        item_desc_chn,\n",
    "        cast(order_qty as int) as order_qty,\n",
    "        cast(dm_order_qty as int) as dm_order_qty,\n",
    "        {0} as run_date\n",
    "    FROM weekly_forecast_df\n",
    "    \"\"\".replace(\"\\n\", \" \").format(run_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlc.sql(dm_dc_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlc.sql(\"refresh table vartefact.forecast_weekly_forecast_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
