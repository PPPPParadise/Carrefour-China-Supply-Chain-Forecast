{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import datetime\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from openpyxl import Workbook\n",
    "from os.path import abspath\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_location = abspath('spark-warehouse')\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = '--jars /data/jupyter/kudu-spark2_2.11-1.8.0.jar pyspark-shell'\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Generate order forecast file\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"spark.driver.memory\", '8g') \\\n",
    "    .config(\"spark.executor.memory\", '6g') \\\n",
    "    .config(\"spark.num.executors\", '14') \\\n",
    "    .config(\"hive.exec.compress.output\", 'false') \\\n",
    "    .config(\"spark.sql.crossJoin.enabled\", 'true') \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", '-1') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_date = datetime.datetime.strptime(\"20190902\", '%Y%m%d').date()\n",
    "w1_start_date = run_date\n",
    "w2_start_date = run_date + timedelta(weeks=1)\n",
    "w3_start_date = run_date + timedelta(weeks=2)\n",
    "w4_start_date = run_date + timedelta(weeks=3)\n",
    "w5_start_date = run_date + timedelta(weeks=4)\n",
    "w6_start_date = run_date + timedelta(weeks=5)\n",
    "w7_start_date = run_date + timedelta(weeks=6)\n",
    "w8_start_date = run_date + timedelta(weeks=7)\n",
    "w9_start_date = run_date + timedelta(weeks=8)\n",
    "w10_start_date = run_date + timedelta(weeks=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_sql = \"\"\"\n",
    "    SELECT\n",
    "        dc.holding_code,\n",
    "        dc.primary_barcode,\n",
    "        dc.dept_code,\n",
    "        dc.item_code,\n",
    "        dc.sub_code,\n",
    "        dc.item_name_local,\n",
    "        dc.item_name_english\n",
    "    FROM vartefact.v_forecast_inscope_dc_item_details dc\n",
    "\"\"\".replace(\"\\n\", \" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = sqlc.sql(items_sql).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross docking items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdock_orders_sql = \"\"\"\n",
    "    SELECT\n",
    "        dc.dept_code,\n",
    "        dc.item_code,\n",
    "        dc.sub_code,\n",
    "        wst.date_key week_start_day,\n",
    "        sum(\n",
    "            ceil(\n",
    "                coalesce(ord.order_qty, 0) * (2 - coalesce(sl.service_level, 1)) / dc.qty_per_box\n",
    "            )\n",
    "        ) order_qty,\n",
    "        sum(ceil(coalesce(dm.order_qty, 0) / dc.qty_per_box)) dm_qty\n",
    "    FROM\n",
    "        vartefact.forecast_calendar cal\n",
    "        INNER JOIN vartefact.forecast_calendar wst ON wst.week_index = cal.week_index\n",
    "        AND wst.weekday_short = 'Mon'\n",
    "        INNER JOIN vartefact.v_forecast_inscope_dc_item_details dc ON dc.rotation = 'X'\n",
    "        LEFT OUTER JOIN vartefact.forecast_xdock_orders ord ON ord.order_day = cal.date_key\n",
    "        AND ord.item_code = dc.item_code\n",
    "        AND ord.sub_code = dc.sub_code\n",
    "        AND ord.dept_code = dc.dept_code\n",
    "        AND ord.order_day >='{0}'\n",
    "        AND ord.order_day <'{2}'\n",
    "        LEFT OUTER JOIN vartefact.forecast_dm_orders dm ON ord.store_code = dm.store_code\n",
    "        AND ord.dept_code = dm.dept_code\n",
    "        AND ord.item_code = dm.item_code\n",
    "        AND ord.sub_code = dm.sub_code\n",
    "        AND ord.order_day = dm.first_order_date\n",
    "        AND dm.first_order_date >='{0}'\n",
    "        AND dm.first_order_date <'{2}'\n",
    "        LEFT OUTER JOIN vartefact.service_level_safety2_vinc sl ON ord.item_code = sl.item_code\n",
    "        AND ord.sub_code = sl.sub_code\n",
    "        AND ord.dept_code = sl.dept_code\n",
    "    WHERE\n",
    "        wst.date_key >='{0}'\n",
    "        and wst.date_key <='{1}'\n",
    "    GROUP BY\n",
    "        dc.dept_code,\n",
    "        dc.item_code,\n",
    "        dc.sub_code,\n",
    "        wst.date_key \n",
    "        \"\"\".replace(\"\\n\", \" \") \\\n",
    "        .format(\n",
    "                w1_start_date.strftime(\"%Y%m%d\"), \n",
    "                w9_start_date.strftime(\"%Y%m%d\"),\n",
    "                w10_start_date.strftime(\"%Y%m%d\"))\n",
    "\n",
    "xdock_orders = sqlc.sql(xdock_orders_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdock_orders_df = xdock_orders.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_orders_sql = \"\"\"\n",
    "    SELECT\n",
    "        dc.dept_code,\n",
    "        dc.item_code,\n",
    "        dc.sub_code,\n",
    "        wst.date_key week_start_day,\n",
    "        sum(\n",
    "            ceil(\n",
    "                coalesce(ord.order_qty, 0) * (2 - coalesce(sl.service_level, 1)) / dc.qty_per_box\n",
    "            )\n",
    "        ) order_qty,\n",
    "        sum(ceil(coalesce(dm.order_qty, 0) / dc.qty_per_box)) dm_qty\n",
    "    FROM\n",
    "        vartefact.forecast_calendar cal\n",
    "        INNER JOIN vartefact.forecast_calendar wst ON wst.week_index = cal.week_index\n",
    "        AND wst.weekday_short = 'Mon'\n",
    "        INNER JOIN vartefact.v_forecast_inscope_dc_item_details dc ON dc.rotation != 'X'\n",
    "        LEFT OUTER JOIN vartefact.forecast_dc_orders ord ON ord.order_day = cal.date_key\n",
    "        AND ord.item_code = dc.item_code\n",
    "        AND ord.sub_code = dc.sub_code\n",
    "        AND ord.dept_code = dc.dept_code\n",
    "        AND ord.order_day >='{0}'\n",
    "        AND ord.order_day <'{2}'\n",
    "        LEFT OUTER JOIN vartefact.forecast_dm_dc_orders dm ON ord.dept_code = dm.dept_code\n",
    "        AND ord.item_code = dm.item_code\n",
    "        AND ord.sub_code = dm.sub_code\n",
    "        AND ord.order_day = dm.first_order_date\n",
    "        AND dm.first_order_date >='{0}'\n",
    "        AND dm.first_order_date <'{2}'\n",
    "        LEFT OUTER JOIN vartefact.service_level_safety2_vinc sl ON ord.item_code = sl.item_code\n",
    "        AND ord.sub_code = sl.sub_code\n",
    "        AND ord.dept_code = sl.dept_code\n",
    "    WHERE\n",
    "        wst.date_key >='{0}'\n",
    "        and wst.date_key <='{1}'\n",
    "    GROUP BY\n",
    "        dc.dept_code,\n",
    "        dc.item_code,\n",
    "        dc.sub_code,\n",
    "        wst.date_key\n",
    "        \"\"\".replace(\"\\n\", \" \") \\\n",
    "        .format(\n",
    "                w1_start_date.strftime(\"%Y%m%d\"), \n",
    "                w9_start_date.strftime(\"%Y%m%d\"),\n",
    "                w10_start_date.strftime(\"%Y%m%d\"))\n",
    "\n",
    "\n",
    "dc_orders = sqlc.sql(dc_orders_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_orders_df = dc_orders.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forecast = pd.concat([xdock_orders_df, dc_orders_df],ignore_index=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/data/jupyter/ws_house/Carrefour_DM\"\n",
    "\n",
    "run_date_str = run_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "w1_date_str = w1_start_date.strftime(\"%Y%m%d\")\n",
    "w2_date_str = w2_start_date.strftime(\"%Y%m%d\")\n",
    "w3_date_str = w3_start_date.strftime(\"%Y%m%d\")\n",
    "w4_date_str = w4_start_date.strftime(\"%Y%m%d\")\n",
    "w5_date_str = w5_start_date.strftime(\"%Y%m%d\")\n",
    "w6_date_str = w6_start_date.strftime(\"%Y%m%d\")\n",
    "w7_date_str = w7_start_date.strftime(\"%Y%m%d\")\n",
    "w8_date_str = w8_start_date.strftime(\"%Y%m%d\")\n",
    "w9_date_str = w9_start_date.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_qty (df, row, week_start_day):\n",
    "    df_line = all_forecast[(all_forecast[\"item_code\"] == row.item_code) \n",
    "                        & (all_forecast[\"sub_code\"] == row.sub_code)\n",
    "                       & (all_forecast[\"dept_code\"] == row.dept_code)\n",
    "                       & (all_forecast[\"week_start_day\"] == week_start_day)]\n",
    "    if len(df_line) > 0:\n",
    "        return str(df_line['order_qty'].iloc[0])\n",
    "    else:\n",
    "        return \"0\"\n",
    "\n",
    "def get_dm_qty (df, row, week_start_day):\n",
    "    df_line = all_forecast[(all_forecast[\"item_code\"] == row.item_code) \n",
    "                        & (all_forecast[\"sub_code\"] == row.sub_code)\n",
    "                       & (all_forecast[\"dept_code\"] == row.dept_code)\n",
    "                       & (all_forecast[\"week_start_day\"] == week_start_day)]\n",
    "\n",
    "    if len(df_line) > 0:\n",
    "        return str(df_line['dm_qty'].iloc[0])\n",
    "    else:\n",
    "        return \"0\"\n",
    "    \n",
    "    \n",
    "def write_forecast_file(con_holding, supplier_name, forecast_file, items_df, all_forecast):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.append(\n",
    "        ['Supplier_name','Barcode','Department_code','Item_code',\n",
    "         'Sub_code','Item_desc_chn','Item_desc_eng',\n",
    "         f'Week1_{w1_date_str}_Permanent_Box', f'Week1_{w1_date_str}_DM_Box',\n",
    "         f'Week2_{w2_date_str}_Permanent_Box', f'Week2_{w2_date_str}_DM_Box',\n",
    "         f'Week3_{w3_date_str}_Permanent_Box', f'Week3_{w3_date_str}_DM_Box',\n",
    "         f'Week4_{w4_date_str}_Permanent_Box', f'Week4_{w4_date_str}_DM_Box',\n",
    "         f'Week5_{w5_date_str}_Permanent_Box', f'Week5_{w5_date_str}_DM_Box',\n",
    "         f'Week6_{w6_date_str}_Permanent_Box', f'Week6_{w6_date_str}_DM_Box',\n",
    "         f'Week7_{w7_date_str}_Permanent_Box', f'Week7_{w7_date_str}_DM_Box',\n",
    "         f'Week8_{w8_date_str}_Permanent_Box', f'Week8_{w8_date_str}_DM_Box',\n",
    "         f'Week9_{w9_date_str}_Permanent_Box', f'Week9_{w9_date_str}_DM_Box '])\n",
    "\n",
    "    for index, row in items_df[items_df[\"holding_code\"] == con_holding].iterrows():\n",
    "        ws.append([supplier_name, row.primary_barcode,\n",
    "                   row.dept_code, row.item_code, row.sub_code, row.item_name_local, row.item_name_english,\n",
    "                   get_order_qty(all_forecast, row, w1_date_str), get_dm_qty(all_forecast, row, w1_date_str),\n",
    "                   get_order_qty(all_forecast, row, w2_date_str), get_dm_qty(all_forecast, row, w2_date_str),\n",
    "                   get_order_qty(all_forecast, row, w3_date_str), get_dm_qty(all_forecast, row, w3_date_str),\n",
    "                   get_order_qty(all_forecast, row, w4_date_str), get_dm_qty(all_forecast, row, w4_date_str),\n",
    "                   get_order_qty(all_forecast, row, w5_date_str), get_dm_qty(all_forecast, row, w5_date_str),\n",
    "                   get_order_qty(all_forecast, row, w6_date_str), get_dm_qty(all_forecast, row, w6_date_str),\n",
    "                   get_order_qty(all_forecast, row, w7_date_str), get_dm_qty(all_forecast, row, w7_date_str),\n",
    "                   get_order_qty(all_forecast, row, w8_date_str), get_dm_qty(all_forecast, row, w8_date_str),\n",
    "                   get_order_qty(all_forecast, row, w9_date_str), get_dm_qty(all_forecast, row, w9_date_str)])\n",
    "\n",
    "    wb.save(output_path + '/' + forecast_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_holding = \"700\"\n",
    "supplier_name = \"Unilever Services (Hefei) Co. Ltd.\"\n",
    "\n",
    "forecast_file = f\"Carrefour_Order_Forecast_DC_level_{con_holding}_{run_date_str}.xlsx\"\n",
    "\n",
    "write_forecast_file(con_holding, supplier_name, forecast_file, items_df, all_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "con_holding = \"002\"\n",
    "supplier_name = \"Shanghai Nestle products Service Co.,Ltd\"\n",
    "\n",
    "forecast_file = f\"Carrefour_Order_Forecast_DC_level_{con_holding}_{run_date_str}.xlsx\"\n",
    "\n",
    "write_forecast_file(con_holding, supplier_name, forecast_file, items_df, all_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_holding = \"693\"\n",
    "supplier_name = \"Procter&Gamble (China) Sales Co.,Ltd.\"\n",
    "\n",
    "forecast_file = f\"Carrefour_Order_Forecast_DC_level_{con_holding}_{run_date_str}.xlsx\"\n",
    "\n",
    "write_forecast_file(con_holding, supplier_name, forecast_file, items_df, all_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
